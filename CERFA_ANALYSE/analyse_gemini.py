#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
analyse_gemini.py ‚Äî Analyse d'un CERFA CU (13410*12)
Gemini 2.5 Flash ‚Üí JSON structur√© conforme au CUA Builder
avec pr√©-extraction INSEE robuste, validation + relance intelligente
"""

import os, json, re, time, random, logging
from pathlib import Path
from pypdf import PdfReader
import google.generativeai as genai
import pandas as pd
from dotenv import load_dotenv

# Import de la pr√©-analyse compl√®te
from CERFA_ANALYSE.pre_analyse_cerfa import pre_analyse_cerfa

# ============================================================
# CONFIG
# ============================================================
load_dotenv()
logging.basicConfig(level=logging.INFO, format="%(levelname)s | %(message)s")
logger = logging.getLogger("cerfa_analyse")

MODEL_PRIMARY = "gemini-2.5-pro"
MODEL_FALLBACK = "gemini-2.5-flash"
# Chemin vers le CSV INSEE : CONFIG est au m√™me niveau que CERFA_ANALYSE
INSEE_CSV = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "CONFIG", "v_commune_2025.csv"))

# ============================================================
# INDICES VISUELS DE LOCALISATION
# ============================================================
VISUAL_LOCATION_HINTS = """
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìç GUIDE DE LOCALISATION VISUELLE - CERFA 13410*12
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìå EN-T√äTE DU CERTIFICAT (PAGE 1, coin sup√©rieur droit)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Cadre r√©serv√© √† la mairie du lieu du projet            ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ C U  [Dpt] [Commune] [Ann√©e] [N¬∞ de dossier]          ‚îÇ
‚îÇ     033    234       25      00078                     ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ La pr√©sente d√©claration a √©t√© re√ßue √† la mairie       ‚îÇ
‚îÇ le [JJ]/[MM]/[AAAA]                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Structure header_cu :
‚Ä¢ D√©partement : 3 chiffres (ex: 033 = Gironde)
‚Ä¢ Commune : 3 chiffres (ex: 234 = code commune)
‚Ä¢ Ann√©e : 2 chiffres (ex: 25 = 2025)
‚Ä¢ N¬∞ dossier : 5 chiffres (ex: 00078)

Code insee : [Dpt][Commune]
Exemple : 033234 = 33234, le code insee est √† 5 chiffres (33 + 234)

üìå TYPE DE CERTIFICAT (PAGE 1, section 1)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1 Objet de la demande de certificat d'urbanisme       ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ ‚òë a) Certificat d'urbanisme d'information             ‚îÇ
‚îÇ ‚òê b) Certificat d'urbanisme op√©rationnel              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

R√®gle : Si case "a)" coch√©e ‚Üí type_cu = "CUa"
        Si case "b)" coch√©e ‚Üí type_cu = "CUb"

üìå IDENTIT√â DU DEMANDEUR (PAGE 1, section 2)

Pour un PARTICULIER (section 2.1) :
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2.1 Vous √™tes un particulier                          ‚îÇ
‚îÇ Nom : [NOM]          Pr√©nom : [PRENOM]                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Pour une PERSONNE MORALE (section 2.2) :
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2.2 Vous √™tes une personne morale                     ‚îÇ
‚îÇ D√©nomination : [RAISON SOCIALE]                        ‚îÇ
‚îÇ Raison sociale : [TYPE]                                ‚îÇ
‚îÇ N¬∞ SIRET : [14 CHIFFRES]  Type : [SARL/SA/SCI...]    ‚îÇ
‚îÇ Repr√©sentant : Nom [NOM]  Pr√©nom [PRENOM]             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üìå ADRESSE DU TERRAIN (PAGE 2, section 4.1)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4.1 Adresse du (ou des) terrain(s)                    ‚îÇ
‚îÇ Num√©ro : [N¬∞]     Voie : [NOM DE RUE]                 ‚îÇ
‚îÇ Lieu-dit : [LIEU-DIT si pr√©sent]                      ‚îÇ
‚îÇ Localit√© : [NOM COMMUNE]     ‚Üê NOM DE LA COMMUNE ICI  ‚îÇ
‚îÇ Code postal : [5 CHIFFRES]   ‚Üê Dept = 2 premiers      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚ö†Ô∏è ATTENTION : L'adresse du terrain (section 4) est DIFF√âRENTE de
              l'adresse du demandeur (section 3, page 2)

üìå R√âF√âRENCES CADASTRALES (PAGE 4, section 4.2)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4.2 R√©f√©rences cadastrales :                           ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ Section : [AI]  Num√©ro : [0310]  Superficie : 5755 m¬≤ ‚îÇ
‚îÇ Section : [AI]  Num√©ro : [0058]  Superficie : 256 m¬≤  ‚îÇ
‚îÇ Section : [AI]  Num√©ro : [0311]  Superficie : 1368 m¬≤ ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ Superficie totale du terrain (en m¬≤) : 12310          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Format parcelles :
‚Ä¢ Section : 1-2 LETTRES MAJUSCULES (ex: AI, AC, ZA)
‚Ä¢ Num√©ro : 4 CHIFFRES avec z√©ros initiaux (ex: 0310, 0058)
‚Ä¢ Superficie : nombre entier en m¬≤

‚ö†Ô∏è Si > 1 parcelles‚Üí CONTINUER SUR PAGE 4

üìå NUM√âRO CU COMPLET (√† reconstruire)
Format final attendu : [Dept]-[Commune]-20[Ann√©e]-X[Dossier]
Exemple : 033-234-2025-X00078

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ö†Ô∏è R√àGLES CRITIQUES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
1. Le header_cu se trouve TOUJOURS page 1, cadre sup√©rieur droit
2. La commune_nom vient de section 4.1 "Localit√©" (PAS section 3)
3. TOUJOURS v√©rifier la page annexe pour parcelles suppl√©mentaires
4. La superficie totale DOIT √™tre >= somme des surfaces individuelles
5. Ne JAMAIS inventer de valeurs absentes du document
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
"""

# ============================================================
# OUTILS
# ============================================================
def extract_json(text):
    i, j = text.find("{"), text.rfind("}")
    if i == -1 or j == -1:
        return None
    raw = text[i:j+1]
    try:
        return json.loads(raw)
    except Exception:
        raw = re.sub(r",\s*}", "}", raw)
        raw = re.sub(r",\s*]", "]", raw)
        try:
            return json.loads(raw)
        except:
            return None

def get_nested_value(data, keys):
    """R√©cup√®re une valeur imbriqu√©e dans un dict via une liste de cl√©s"""
    for k in keys:
        if '[' in k:  # Gestion listes (ex: "references_cadastrales[0].section")
            k_name, idx = k.split('[')
            idx = int(idx.rstrip(']'))
            if isinstance(data, dict) and k_name in data:
                data = data[k_name]
                if isinstance(data, list) and len(data) > idx:
                    data = data[idx]
                else:
                    return None
            else:
                return None
        else:
            data = data.get(k) if isinstance(data, dict) else None
        if data is None:
            return None
    return data

def set_nested_value(data, keys, value):
    """D√©finit une valeur imbriqu√©e dans un dict via une liste de cl√©s"""
    for i, k in enumerate(keys[:-1]):
        if '[' in k:
            k_name, idx = k.split('[')
            idx = int(idx.rstrip(']'))
            if k_name not in data:
                data[k_name] = []
            while len(data[k_name]) <= idx:
                data[k_name].append({})
            data = data[k_name][idx]
        else:
            if k not in data:
                data[k] = {}
            data = data[k]
    
    final_key = keys[-1]
    if '[' in final_key:
        k_name, idx = final_key.split('[')
        idx = int(idx.rstrip(']'))
        if k_name not in data:
            data[k_name] = []
        while len(data[k_name]) <= idx:
            data[k_name].append(None)
        data[k_name][idx] = value
    else:
        data[final_key] = value

def merge_extraction_results(base_data, new_data, missing_fields):
    """
    Fusionne en privil√©giant les champs non-null de base_data,
    sauf pour les champs explicitement manquants √† corriger
    """
    merged = json.loads(json.dumps(base_data))  # Deep copy
    
    for field in missing_fields:
        keys = field.split('.')
        new_value = get_nested_value(new_data, keys)
        if new_value is not None:
            set_nested_value(merged, keys, new_value)
            logger.info(f"  ‚Ü≥ Champ compl√©t√©: {field}")
    
    return merged

# ============================================================
# PROMPTS
# ============================================================
BASE_PROMPT = f"""Tu es un expert en lecture de formulaires CERFA et en extraction d'informations structur√©es.

Analyse le document PDF fourni (CERFA 13410*12) et renvoie **UNIQUEMENT** un JSON strict conforme au sch√©ma ci-dessous.

‚ö†Ô∏è NE FOURNIS AUCUN TEXTE HORS DU JSON. NE COMMENTE RIEN. N'EXPLIQUE RIEN.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
SCH√âMA JSON STRICT √Ä RESPECTER :
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
{{
  "cerfa_reference": "13410*12",
  "commune_nom": null,
  "commune_insee": null,
  "departement_code": null,
  "numero_cu": null,
  "type_cu": null,
  "date_depot": null,
  "demandeur": {{
    "type": "particulier" ou "personne_morale",
    "nom": null,
    "prenom": null,
    "denomination": null,
    "representant_nom": null,
    "representant_prenom": null,
    "siret": null,
    "adresse": {{
      "numero": null,
      "voie": null,
      "lieu_dit": null,
      "code_postal": null,
      "ville": null,
      "email": null,
      "telephone": null
    }}
  }},
  "adresse_terrain": {{
    "numero": null,
    "voie": null,
    "lieu_dit": null,
    "code_postal": null,
    "ville": null
  }},
  "references_cadastrales": [{{"section": null, "numero": null, "surface_m2": null}}],
  "superficie_totale_m2": null,
  "header_cu": {{
    "dept": null,
    "commune_code": null,
    "annee": null,
    "numero_dossier": null
  }}
}}

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
R√àGLES D'EXTRACTION :
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
1. Si le cadre ¬´ Vous √™tes un particulier ¬ª (2.1) est coch√© ‚Üí type = "particulier"
   - Extraire : nom, pr√©nom, adresse compl√®te, email, t√©l√©phone.

2. Si le cadre ¬´ Vous √™tes une personne morale ¬ª (2.2) est coch√© ‚Üí type = "personne_morale"
   - Extraire : d√©nomination, SIRET, type (SARL/SCI...), nom et pr√©nom du repr√©sentant l√©gal.
   - Extraire √©galement l'adresse, email, t√©l√©phone si pr√©sents.

3. L'adresse du demandeur vient de la section 3 du CERFA.
   L'adresse du terrain vient de la section 4.1 (page 2).

4. Extraire toutes les r√©f√©rences cadastrales (section 4.2 et annexes).
   - Chaque objet doit avoir `section`, `numero`, `surface_m2`.
   - Calculer la `superficie_totale_m2` si possible.

5. Construire le num√©ro complet du certificat :
   [dept]-[commune_code]-20[annee]-X[numero_dossier]

6. Toujours inclure toutes les cl√©s, m√™me vides (null).

{VISUAL_LOCATION_HINTS}

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
NE PAS :
- inventer de donn√©es
- traduire les valeurs (garde les noms et adresses fran√ßais)
- omettre des cl√©s
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
"""

# ============================================================
# VALIDATION
# ============================================================
EXPECTED_FIELDS = {
    "cerfa_reference", "commune_nom", "departement_code",
    "numero_cu", "type_cu", "date_depot",
    "demandeur", "adresse_terrain", "references_cadastrales",
    "superficie_totale_m2", "header_cu"
}

FIELD_TRANSLATIONS = {
    "cerfa_reference": "la r√©f√©rence CERFA",
    "commune_nom": "le nom de la commune (section 4.1 Localit√©)",
    "departement_code": "le code du d√©partement",
    "numero_cu": "le num√©ro du certificat d'urbanisme",
    "type_cu": "le type de certificat (CUa ou CUb)",
    "date_depot": "la date de d√©p√¥t",
    "demandeur": "les informations compl√®tes du demandeur",
    "demandeur.type": "le type de demandeur (particulier ou personne_morale, section 2.1 ou 2.2)",
    "demandeur.nom": "le nom du demandeur ou du repr√©sentant (section 2)",
    "demandeur.adresse": "l'adresse compl√®te du demandeur (section 3)",
    "demandeur.adresse.code_postal": "le code postal du demandeur (section 3)",
    "demandeur.adresse.ville": "la ville du demandeur (section 3)",
    "adresse_terrain": "l'adresse du terrain (section 4.1)",
    "references_cadastrales": "les parcelles cadastrales avec section, num√©ro et surface (section 4.2 + annexes)",
    "references_cadastrales[].section": "la section cadastrale",
    "references_cadastrales[].numero": "le num√©ro de parcelle",
    "superficie_totale_m2": "la superficie totale du terrain (section 4.2)",
    "header_cu": "l'en-t√™te du num√©ro CU (page 1, cadre sup√©rieur droit)",
    "header_cu.dept": "le code d√©partement (3 chiffres, ex: 033)",
    "header_cu.commune_code": "le code commune (3 chiffres, ex: 234)",
    "header_cu.annee": "l'ann√©e (2 chiffres, ex: 25)",
    "header_cu.numero_dossier": "le num√©ro de dossier (5 chiffres, ex: 00078)"
}

def validate_cerfa_json(data):
    """
    Valide que le JSON contient tous les champs essentiels.
    V√©rifie aussi les sous-structures (demandeur, adresse_terrain, r√©f√©rences cadastrales).
    """
    missing = []
    
    # Validation des champs de premier niveau
    for f in EXPECTED_FIELDS:
        if f not in data or data[f] in (None, "", []):
            missing.append(f)
    
    # Validation sp√©cifique du demandeur
    if "demandeur" in data and isinstance(data["demandeur"], dict):
        demandeur = data["demandeur"]
        # Type obligatoire
        if not demandeur.get("type"):
            missing.append("demandeur.type")
        # Nom obligatoire (particulier ou repr√©sentant)
        if not demandeur.get("nom"):
            missing.append("demandeur.nom")
        # Adresse obligatoire
        if not demandeur.get("adresse") or not isinstance(demandeur["adresse"], dict):
            missing.append("demandeur.adresse")
        elif demandeur.get("adresse"):
            # V√©rifier les champs minimums de l'adresse
            adresse = demandeur["adresse"]
            if not adresse.get("code_postal"):
                missing.append("demandeur.adresse.code_postal")
            if not adresse.get("ville"):
                missing.append("demandeur.adresse.ville")
    
    # Validation des r√©f√©rences cadastrales
    if "references_cadastrales" in data and isinstance(data["references_cadastrales"], list):
        if len(data["references_cadastrales"]) > 0:
            for idx, ref in enumerate(data["references_cadastrales"]):
                if not isinstance(ref, dict):
                    continue
                if not ref.get("section"):
                    missing.append(f"references_cadastrales[{idx}].section")
                if not ref.get("numero"):
                    missing.append(f"references_cadastrales[{idx}].numero")
    
    # Validation du header_cu
    if "header_cu" in data and isinstance(data["header_cu"], dict):
        header = data["header_cu"]
        required_header_fields = ["dept", "commune_code", "annee", "numero_dossier"]
        for field in required_header_fields:
            if not header.get(field):
                missing.append(f"header_cu.{field}")
    
    if missing:
        logger.warning(f"‚ö†Ô∏è Champs manquants ou vides : {missing}")
        return False, missing
    
    return True, []

def missing_fields_message(missing):
    """G√©n√®re un message d√©crivant les champs manquants"""
    parts = [FIELD_TRANSLATIONS.get(f, f) for f in missing]
    return "Certains champs essentiels sont absents : " + ", ".join(parts) + "."

def build_correction_prompt(previous_data, missing):
    """Construit un prompt de correction avec contexte des donn√©es d√©j√† extraites"""
    # Extraire les donn√©es d√©j√† valid√©es (non manquantes)
    validated_data = {}
    for key, value in previous_data.items():
        # Garder seulement les champs qui ne sont pas dans missing
        if key not in [m.split('.')[0] for m in missing]:
            validated_data[key] = value
    
    correction_hint = f"""
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
CONTEXTE : CORRECTION DE CHAMPS MANQUANTS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

DONN√âES D√âJ√Ä EXTRAITES (√Ä CONSERVER TELLES QUELLES) :
{json.dumps(validated_data, indent=2, ensure_ascii=False)}

CHAMPS √Ä COMPL√âTER UNIQUEMENT :
{missing_fields_message(missing)}

INSTRUCTIONS :
- Relis attentivement le document PDF en suivant le GUIDE DE LOCALISATION VISUELLE
- Compl√®te UNIQUEMENT les champs manquants list√©s ci-dessus
- Renvoie le JSON COMPLET en incluant :
  1. Toutes les donn√©es d√©j√† extraites ci-dessus (inchang√©es)
  2. Les champs manquants maintenant compl√©t√©s
- Ne modifie PAS les donn√©es d√©j√† valid√©es
- Respecte strictement le sch√©ma JSON
"""
    return correction_hint

# ============================================================
# AFFICHAGE ET CONFIRMATION PR√â-ANALYSE
# ============================================================
def display_pre_analyse_results(pre_analyse_result):
    """
    Affiche les r√©sultats de la pr√©-analyse de mani√®re lisible
    """
    print("\n" + "="*70)
    print("üìä R√âSULTATS DE LA PR√â-ANALYSE")
    print("="*70)
    
    # INSEE
    insee = pre_analyse_result.get('insee', {})
    print("\nüìç CODE INSEE DE LA COMMUNE")
    print("-" * 70)
    if insee.get('code'):
        print(f"  Code INSEE : {insee['code']}")
        print(f"  Confiance  : {insee.get('confidence', 'unknown')}")
        print(f"  M√©thode    : {insee.get('method', 'unknown')}")
        if insee.get('commune_nom_officiel'):
            print(f"  Commune    : {insee['commune_nom_officiel']}")
    else:
        print("  ‚ùå Code INSEE non trouv√©")
    
    # Parcelles
    parcelles = pre_analyse_result.get('parcelles', [])
    print(f"\nüìã PARCELLES CADASTRALES ({len(parcelles)} trouv√©e(s))")
    print("-" * 70)
    if parcelles:
        for idx, parcelle in enumerate(parcelles, 1):
            section = parcelle.get('section', 'N/A')
            numero = parcelle.get('numero', 'N/A')
            print(f"  {idx}. Section: {section:4s} | Num√©ro: {numero}")
    else:
        print("  ‚ùå Aucune parcelle trouv√©e")
    
    # Superficie
    superficie = pre_analyse_result.get('superficie_totale_m2')
    print(f"\nüìè SUPERFICIE TOTALE DU TERRAIN")
    print("-" * 70)
    if superficie:
        print(f"  Superficie : {superficie:,} m¬≤")
    else:
        print("  ‚ùå Superficie non trouv√©e")
    
    print("\n" + "="*70)
    
    return True

def ask_user_confirmation():
    """
    Demande confirmation √† l'utilisateur avant de continuer
    """
    while True:
        response = input("\n‚ùì Voulez-vous continuer avec l'analyse compl√®te du CERFA ? (o/n) : ").strip().lower()
        if response in ['o', 'oui', 'y', 'yes']:
            return True
        elif response in ['n', 'non', 'no']:
            return False
        else:
            print("‚ö†Ô∏è  R√©ponse invalide. Veuillez r√©pondre 'o' (oui) ou 'n' (non).")

# ============================================================
# MAIN PIPELINE
# ============================================================
def analyse_cerfa(pdf_path, out_json="cerfa_result.json", max_retries=1, interactive=True):
    """
    Analyse compl√®te d'un CERFA avec extraction robuste
    
    Args:
        pdf_path: Chemin du PDF CERFA
        out_json: Fichier de sortie JSON
        max_retries: Nombre de tentatives maximum (0 = pas de retry, 2 = 3 essais au total)
        interactive: Si True, affiche les r√©sultats de pr√©-analyse et demande confirmation
    
    Returns:
        dict: R√©sultat complet avec succ√®s, donn√©es, erreurs, m√©tadonn√©es, pr√©-analyse
    """
    genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
    pdf = Path(pdf_path)
    logger.info(f"üìÑ Analyse du fichier {pdf.name}")
    
    # ============================================================
    # √âTAPE 1 : PR√â-ANALYSE COMPL√àTE (INSEE + PARCELLES + SUPERFICIE)
    # ============================================================
    logger.info("="*60)
    logger.info("üéØ √âTAPE 1/4 : PR√â-ANALYSE COMPL√àTE")
    logger.info("="*60)
    logger.info("üìã Extraction simultan√©e : INSEE + Parcelles + Superficie")
    logger.info("   (Analyse des 4 premi√®res pages uniquement)")
    
    pre_analyse_result = pre_analyse_cerfa(pdf_path, MODEL_PRIMARY, MODEL_FALLBACK)
    
    # Affichage des r√©sultats et demande de confirmation
    if interactive:
        display_pre_analyse_results(pre_analyse_result)
        if not ask_user_confirmation():
            logger.info("‚ùå Analyse annul√©e par l'utilisateur")
            return {
                "success": False,
                "data": None,
                "errors": ["user_cancelled"],
                "model_used": None,
                "pre_analyse": pre_analyse_result,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
        logger.info("‚úÖ Confirmation re√ßue, poursuite de l'analyse...")
    else:
        logger.info("üìä R√©sultats pr√©-analyse (mode non-interactif):")
        logger.info(f"   INSEE: {pre_analyse_result.get('insee', {}).get('code', 'N/A')}")
        logger.info(f"   Parcelles: {len(pre_analyse_result.get('parcelles', []))}")
        logger.info(f"   Superficie: {pre_analyse_result.get('superficie_totale_m2', 'N/A')} m¬≤")
    
    # Pr√©parer les donn√©es INSEE pour l'injection (compatibilit√© avec l'ancien format)
    insee_result = {
        'insee': pre_analyse_result.get('insee', {}).get('code'),
        'confidence': pre_analyse_result.get('insee', {}).get('confidence', 'unknown'),
        'method': pre_analyse_result.get('insee', {}).get('method', 'unknown'),
        'commune_nom_officiel': pre_analyse_result.get('insee', {}).get('commune_nom_officiel')
    }
    
    # ============================================================
    # √âTAPE 2 : EXTRACTION COMPL√àTE AVEC RETRY PROGRESSIF
    # ============================================================
    logger.info("="*60)
    logger.info("üìã √âTAPE 2/4 : EXTRACTION COMPL√àTE DU CERFA")
    logger.info("="*60)
    
    # Enrichir le prompt avec les donn√©es de pr√©-analyse
    pre_analyse_context = ""
    if pre_analyse_result.get('insee', {}).get('code'):
        pre_analyse_context += f"\nüìå CONTEXTE DE PR√â-ANALYSE (√† utiliser comme r√©f√©rence) :\n"
        pre_analyse_context += f"- Code INSEE d√©tect√© : {pre_analyse_result['insee']['code']}\n"
        if pre_analyse_result.get('insee', {}).get('commune_nom_officiel'):
            pre_analyse_context += f"- Commune : {pre_analyse_result['insee']['commune_nom_officiel']}\n"
        if pre_analyse_result.get('parcelles'):
            pre_analyse_context += f"- Parcelles d√©tect√©es : {len(pre_analyse_result['parcelles'])} parcelle(s)\n"
            for p in pre_analyse_result['parcelles'][:3]:  # Afficher les 3 premi√®res
                pre_analyse_context += f"  ‚Ä¢ Section {p.get('section', 'N/A')} - Num√©ro {p.get('numero', 'N/A')}\n"
        if pre_analyse_result.get('superficie_totale_m2'):
            pre_analyse_context += f"- Superficie totale d√©tect√©e : {pre_analyse_result['superficie_totale_m2']} m¬≤\n"
        pre_analyse_context += "\n‚ö†Ô∏è Utilise ces informations comme r√©f√©rence, mais v√©rifie-les dans le document complet.\n"
    
    enriched_base_prompt = BASE_PROMPT + pre_analyse_context
    
    model_used = MODEL_PRIMARY
    previous_data = None
    
    def _run_gemini(prompt, model):
        """Ex√©cute une requ√™te Gemini et parse le JSON"""
        try:
            model_instance = genai.GenerativeModel(model)
            response = model_instance.generate_content(
                [
                    {"mime_type": "application/pdf", "data": pdf.read_bytes()},
                    prompt
                ]
            )
            parsed = extract_json(response.text or "")
            if not parsed:
                raise RuntimeError("√âchec parsing JSON Gemini")
            return parsed
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur avec {model}: {e}")
            raise
    
    # Boucle de retry progressive
    for attempt in range(max_retries + 1):
        logger.info(f"\nüîÑ Tentative {attempt + 1}/{max_retries + 1}")
        
        try:
            if attempt == 0:
                # Premier essai avec prompt enrichi (incluant pr√©-analyse)
                logger.info(f"ü§ñ Extraction avec {MODEL_PRIMARY}...")
                data = _run_gemini(enriched_base_prompt, MODEL_PRIMARY)
                model_used = MODEL_PRIMARY
            else:
                # Retry avec prompt enrichi et merge
                logger.info(f"üîß Correction des champs manquants...")
                correction_prompt = enriched_base_prompt + "\n\n" + build_correction_prompt(previous_data, missing)
                
                # Essayer avec le mod√®le qui a march√© pr√©c√©demment
                try:
                    data = _run_gemini(correction_prompt, model_used)
                except Exception:
                    # Fallback si le mod√®le √©choue
                    if model_used == MODEL_PRIMARY:
                        logger.info(f"‚ö†Ô∏è Fallback vers {MODEL_FALLBACK}...")
                        time.sleep(random.uniform(2, 4))
                        data = _run_gemini(correction_prompt, MODEL_FALLBACK)
                        model_used = MODEL_FALLBACK
                    else:
                        raise
                
                # Merge intelligent : garde les bonnes valeurs, compl√®te les manquantes
                data = merge_extraction_results(previous_data, data, missing)
        
        except Exception as e:
            # Fallback vers Flash si Pro √©choue au premier essai
            if attempt == 0 and model_used == MODEL_PRIMARY:
                logger.warning(f"‚ö†Ô∏è √âchec {MODEL_PRIMARY}, fallback vers {MODEL_FALLBACK}...")
                time.sleep(random.uniform(2, 4))
                try:
                    data = _run_gemini(enriched_base_prompt, MODEL_FALLBACK)
                    model_used = MODEL_FALLBACK
                except Exception as e2:
                    logger.error(f"‚ùå √âchec total (Pro et Flash) : {e2}")
                    return {
                        "success": False,
                        "data": None,
                        "errors": ["extraction_failed"],
                        "model_used": None,
                        "insee_extraction": insee_result,
                        "pre_analyse": pre_analyse_result,
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                    }
            else:
                logger.error(f"‚ùå √âchec extraction tentative {attempt + 1}: {e}")
                if attempt == max_retries:
                    return {
                        "success": False,
                        "data": previous_data,
                        "errors": missing if previous_data else ["extraction_failed"],
                        "model_used": model_used,
                        "insee_extraction": insee_result,
                        "pre_analyse": pre_analyse_result,
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                    }
                continue
        
        # Validation
        ok, missing = validate_cerfa_json(data)
        
        if ok:
            logger.info(f"‚úÖ Extraction compl√®te r√©ussie !")
            break
        
        # Acceptation partielle si < 3 champs manquants au dernier essai
        if len(missing) < 3 and attempt == max_retries:
            logger.warning(f"‚ö†Ô∏è Acceptation partielle : {len(missing)} champ(s) manquant(s)")
            break
        
        # Sauvegarder pour le prochain retry
        previous_data = data
        
        if attempt < max_retries:
            logger.warning(f"‚ö†Ô∏è {len(missing)} champ(s) manquant(s), nouvelle tentative...")
            time.sleep(random.uniform(2, 5))
    
    # ============================================================
    # √âTAPE 3 : ENRICHISSEMENT ET NORMALISATION
    # ============================================================
    logger.info("="*60)
    logger.info("üîß √âTAPE 3/4 : ENRICHISSEMENT DES DONN√âES")
    logger.info("="*60)
    
    # Injection des donn√©es de pr√©-analyse (priorit√© haute)
    # INSEE
    if insee_result.get('insee'):
        data['commune_insee'] = insee_result['insee']
        if insee_result.get('commune_nom_officiel'):
            data['commune_nom'] = insee_result['commune_nom_officiel']
        data['_insee_confidence'] = insee_result['confidence']
        data['_insee_method'] = insee_result['method']
        logger.info(f"‚úÖ INSEE inject√©: {insee_result['insee']} (confiance: {insee_result['confidence']})")
    
    # Parcelles (si non trouv√©es ou incompl√®tes dans l'extraction compl√®te)
    pre_parcelles = pre_analyse_result.get('parcelles', [])
    if pre_parcelles:
        extracted_parcelles = data.get('references_cadastrales', [])
        if not extracted_parcelles or len(extracted_parcelles) == 0:
            # Convertir le format de pr√©-analyse vers le format attendu
            data['references_cadastrales'] = [
                {
                    'section': p.get('section'),
                    'numero': p.get('numero'),
                    'surface_m2': None  # Pas de surface dans la pr√©-analyse
                }
                for p in pre_parcelles
            ]
            logger.info(f"‚úÖ Parcelles inject√©es depuis pr√©-analyse: {len(pre_parcelles)} parcelle(s)")
        elif len(pre_parcelles) > len(extracted_parcelles):
            logger.info(f"‚ö†Ô∏è Pr√©-analyse a trouv√© plus de parcelles ({len(pre_parcelles)}) que l'extraction compl√®te ({len(extracted_parcelles)})")
    
    # Superficie (si non trouv√©e dans l'extraction compl√®te)
    pre_superficie = pre_analyse_result.get('superficie_totale_m2')
    if pre_superficie and not data.get('superficie_totale_m2'):
        data['superficie_totale_m2'] = pre_superficie
        logger.info(f"‚úÖ Superficie inject√©e depuis pr√©-analyse: {pre_superficie} m¬≤")
    
    # M√©tadonn√©es
    data["source_file"] = pdf.name
    
    # Normalisation du num√©ro CU
    num = data.get("numero_cu", "")
    if re.match(r"^CU\d{8}X\d+$", num):
        data["numero_cu"] = f"{num[2:4]}-{num[4:7]}-20{num[7:9]}-{num[9:]}"
    
    # Normalisation type_cu
    if data.get("type_cu", "").lower().startswith("info"):
        data["type_cu"] = "CUa"
    
    # R√©sultat final
    final = {
        "success": ok,
        "data": data,
        "errors": missing,
        "model_used": model_used,
        "insee_extraction": insee_result,
        "pre_analyse": pre_analyse_result,
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
    }
    
    # Sauvegarde
    Path(out_json).write_text(json.dumps(final, indent=2, ensure_ascii=False), encoding="utf-8")
    
    logger.info("="*60)
    if ok:
        logger.info(f"‚úÖ SUCC√àS : JSON complet sauvegard√© ‚Üí {out_json}")
    else:
        logger.warning(f"‚ö†Ô∏è PARTIEL : JSON sauvegard√© avec {len(missing)} champ(s) manquant(s) ‚Üí {out_json}")
    logger.info("="*60)
    
    return final

# ============================================================
# CLI (compatible orchestrator)
# ============================================================
if __name__ == "__main__":
    import argparse

    ap = argparse.ArgumentParser(description="Analyse CERFA Gemini (Pro + Fallback Flash) avec pr√©-analyse et extraction robuste")
    ap.add_argument("--pdf", required=True, help="Chemin du PDF CERFA √† analyser")
    ap.add_argument("--out-json", default="cerfa_result.json", help="Chemin de sortie JSON")
    ap.add_argument("--out-dir", default=".", help="Dossier de sortie (compatibilit√© orchestrator)")
    ap.add_argument("--max-retries", type=int, default=2, help="Nombre de retries maximum (d√©faut: 2)")
    ap.add_argument("--non-interactive", action="store_true", help="Mode non-interactif (pas de confirmation)")

    args = ap.parse_args()

    # Appel unique
    analyse_cerfa(args.pdf, args.out_json, max_retries=args.max_retries, interactive=not args.non_interactive)