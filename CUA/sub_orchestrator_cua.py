# -*- coding: utf-8 -*-
"""
sub_orchestrator_cua.py â€” Pipeline de gÃ©nÃ©ration des visualisations et du CUA
------------------------------------------------------
1ï¸âƒ£ GÃ©nÃ¨re la carte 2D Folium Ã  partir du WKT de lâ€™unitÃ© fonciÃ¨re
2ï¸âƒ£ GÃ©nÃ¨re la visualisation 3D Plotly Ã  partir du mÃªme WKT
3ï¸âƒ£ Upload sur Supabase Storage (bucket: visualisation)
4ï¸âƒ£ Construit lâ€™URL publique encodÃ©e pour affichage sur Vercel (/maps?t=...)
5ï¸âƒ£ CrÃ©e un shortlink / QR dynamique
6ï¸âƒ£ Lance la gÃ©nÃ©ration du CUA DOCX avec QR
7ï¸âƒ£ Upload final des artifacts et insertion dans latresne.pipelines
------------------------------------------------------
"""

import os
import json
import base64
import logging
import secrets
import string
from pathlib import Path
from dotenv import load_dotenv
from supabase import create_client

from CUA.carte2d.carte2d_rendu import generer_carte_2d_depuis_wkt
from CUA.map_3d import exporter_visualisation_3d_plotly_from_wkt
from CUA.cua_builder import run_builder

# ============================================================
# ğŸ”§ CONFIGURATION
# ============================================================
load_dotenv()

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SERVICE_KEY") or os.getenv("SUPABASE_SERVICE_ROLE_KEY")
SUPABASE_BUCKET = "visualisation"
KERELIA_BASE_URL = "https://kerelia.fr/maps"

# âœ… Un seul client global
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)-8s | %(message)s",
    datefmt="%H:%M:%S"
)
logger = logging.getLogger("sub_orchestrator_cua")

logger.info("ğŸ”— Client Supabase initialisÃ© avec succÃ¨s.")
logger.info(f"ğŸŒ URL Supabase : {SUPABASE_URL}")

# ============================================================
# ğŸ”— UTILITAIRES
# ============================================================

def generate_short_slug(length=26):
    """GÃ©nÃ¨re un slug alÃ©atoire sÃ©curisÃ© (sans caractÃ¨res ambigus O, 0, I, l)."""
    alphabet = ''.join(ch for ch in string.ascii_letters + string.digits if ch not in 'O0Il')
    return ''.join(secrets.choice(alphabet) for _ in range(length))


def upload_to_supabase(local_path, remote_path, bucket=None):
    """Upload d'un fichier vers Supabase Storage et renvoie l'URL publique."""
    bucket = bucket or SUPABASE_BUCKET
    with open(local_path, "rb") as f:
        supabase.storage.from_(bucket).upload(
            remote_path,
            f.read(),
            {
                "content-type": "application/octet-stream",
                "cache-control": "no-cache",
                "upsert": "true",
            },
        )
    public_url = f"{SUPABASE_URL}/storage/v1/object/public/{bucket}/{remote_path}"
    return public_url


# ============================================================
# ğŸ§© PIPELINE PRINCIPAL
# ============================================================

def generer_visualisations_et_cua_depuis_wkt(wkt_path, out_dir, commune="latresne", code_insee="33234"):
    OUT_DIR = out_dir
    os.makedirs(OUT_DIR, exist_ok=True)
    
    # ============================================================
    # ğŸ”‘ GÃ‰NÃ‰RATION DU SLUG EN AMONT (source de vÃ©ritÃ©)
    # ============================================================
    slug = generate_short_slug()
    logger.info(f"ğŸ”‘ Slug gÃ©nÃ©rÃ© : {slug}")
    
    # ============================================================
    # ğŸ©¹ VÃ‰RIFICATION ROBUSTE DU FICHIER WKT
    # ============================================================
    wkt_path = Path(wkt_path)
    if not wkt_path.exists():
        raise FileNotFoundError(f"âŒ Fichier WKT introuvable : {wkt_path}")
    
    logger.info(f"ğŸš€ Lancement du pipeline global pour le WKT : {wkt_path}")

    # --------------------------------------------------------
    # Ã‰TAPE 1 : CARTE 2D (NOUVEAU MOTEUR)
    # --------------------------------------------------------
    logger.info("\nğŸ“¦ Ã‰TAPE 1/5 : GÃ©nÃ©ration de la carte 2D (nouvelle version)")

    html_2d, metadata_2d = generer_carte_2d_depuis_wkt(
        wkt_path=str(wkt_path),
        code_insee=code_insee,
        inclure_ppri=True,
        ppri_table=f"{commune}.pm1_detaillee_gironde"
    )

    html_2d_path = os.path.join(OUT_DIR, "carte_2d_unite_fonciere.html")
    with open(html_2d_path, "w", encoding="utf-8") as f:
        f.write(html_2d)
    logger.info(f"âœ… Carte 2D (nouvelle version) sauvegardÃ©e : {html_2d_path}")

    # --------------------------------------------------------
    # Ã‰TAPE 2 : CARTE 3D
    # --------------------------------------------------------
    logger.info("\nğŸ“¦ Ã‰TAPE 2/5 : GÃ©nÃ©ration de la visualisation 3D Plotly")
    res3d = exporter_visualisation_3d_plotly_from_wkt(
        wkt_path=wkt_path,
        output_dir=OUT_DIR,
        exaggeration=1.5
    )
    path_3d = res3d["path"]
    logger.info(f"âœ… Carte 3D gÃ©nÃ©rÃ©e : {path_3d}")

    # --------------------------------------------------------
    # Ã‰TAPE 3 : UPLOAD SUPABASE (cartes)
    # --------------------------------------------------------
    logger.info("\nğŸ“¦ Ã‰TAPE 3/5 : Upload des cartes sur Supabase...")
    # âœ… Utiliser le slug comme rÃ©pertoire distant unique
    remote_dir = slug
    remote_2d = f"{remote_dir}/carte_2d.html"
    remote_3d = f"{remote_dir}/carte_3d.html"

    url_2d = upload_to_supabase(html_2d_path, remote_2d)
    url_3d = upload_to_supabase(path_3d, remote_3d)

    logger.info(f"ğŸŒ URL publique 2D : {url_2d}")
    logger.info(f"ğŸŒ URL publique 3D : {url_3d}")

    # --------------------------------------------------------
    # Ã‰TAPE 4 : CONSTRUCTION DU LIEN ENCODED + SHORTLINK
    # --------------------------------------------------------
    logger.info("\nğŸ“¦ Ã‰TAPE 4/5 : Construction du lien encodÃ© et du QR dynamique")
    payload = {"carte2d": url_2d, "carte3d": url_3d, "commune": commune}
    token = base64.urlsafe_b64encode(json.dumps(payload).encode()).decode()
    maps_page_url = f"{KERELIA_BASE_URL}?t={token}"

    # âœ… Utiliser le slug dÃ©jÃ  gÃ©nÃ©rÃ© (shortlinks dans public)
    logger.info(f"ğŸ§© Insertion du shortlink dans public.shortlinks (slug={slug})...")
    try:
        response = supabase.schema("public").table("shortlinks").upsert({
            "slug": slug,
            "target_url": maps_page_url
        }).execute()
        logger.info(f"âœ… Shortlink crÃ©Ã© (status={getattr(response, 'status_code', '?')}) : https://kerelia.fr/m/{slug}")
        qr_url = f"https://kerelia.fr/m/{slug}"
    except Exception as e:
        logger.warning(f"âš ï¸ Erreur lors de la crÃ©ation du shortlink : {e}")
        qr_url = maps_page_url

    # ============================================================
    # ğŸ“„ Ã‰TAPE 5 : GÃ©nÃ©ration du CUA DOCX
    # ============================================================
    logger.info("\nğŸ“¦ Ã‰TAPE 5/5 : GÃ©nÃ©ration du CUA DOCX avec QR dynamique")

    BASE_DIR = os.path.dirname(__file__)

    cerfa_path = os.path.join(OUT_DIR, "cerfa_result.json")
    intersections_files = list(Path(OUT_DIR).glob("rapport_intersections_*.json"))
    if intersections_files:
        intersections_path = str(max(intersections_files, key=lambda p: p.stat().st_mtime))
        logger.info(f"ğŸ“‘ Rapport d'intersections utilisÃ© : {intersections_path}")
    else:
        raise FileNotFoundError(f"âŒ Aucun rapport d'intersections trouvÃ© dans {OUT_DIR}")

    # Utiliser le catalogue avec geom_type
    catalogue_path = os.path.join(BASE_DIR, "..", "catalogues", "catalogue_intersections_tagged.json")
    output_docx_path = os.path.join(OUT_DIR, "CUA_unite_fonciere.docx")
    logo_latresne_path = os.path.join(BASE_DIR, "logos", "logo_latresne.png")
    logo_kerelia_path = os.path.join(BASE_DIR, "logos", "logo_kerelia.png")

    try:
        run_builder(
            cerfa_json=cerfa_path,
            intersections_json=intersections_path,
            catalogue_json=catalogue_path,
            output_path=output_docx_path,
            wkt_path=str(wkt_path),
            logo_first_page=logo_latresne_path,
            signature_logo=logo_kerelia_path,
            qr_url=qr_url,
            plu_nom="PLU de Latresne",
            plu_date_appro="13/02/2017"
        )
        logger.info("âœ… CUA DOCX gÃ©nÃ©rÃ© avec succÃ¨s.")
    except Exception as e:
        logger.error(f"ğŸ’¥ Ã‰chec gÃ©nÃ©ration CUA DOCX : {e}")
        raise

    # ============================================================
    # ğŸ“¤ UPLOAD FINAL DES ARTIFACTS (CUA uniquement)
    # ============================================================
    logger.info("\nğŸ“¤ Upload final du CUA vers Supabase...")

    # Upload du CUA dans le bucket visualisation
    remote_cua = f"{remote_dir}/CUA_unite_fonciere.docx"
    cua_url = upload_to_supabase(output_docx_path, remote_cua, bucket=SUPABASE_BUCKET)
    logger.info(f"ğŸ“ CUA uploadÃ© dans {SUPABASE_BUCKET} : {cua_url}")

    # ============================================================
    # ğŸ”‘ GÃ‰NÃ‰RATION DU TOKEN POUR L'URL /cua?t={token}
    # ============================================================
    logger.info("\nğŸ”‘ GÃ©nÃ©ration du token pour l'URL /cua...")
    payload_cua = {
        "docx": remote_cua  # Chemin relatif dans le bucket visualisation
    }
    token_cua = base64.b64encode(json.dumps(payload_cua).encode()).decode()
    cua_viewer_url = f"https://kerelia.fr/cua?t={token_cua}"
    logger.info(f"âœ… URL CUA gÃ©nÃ©rÃ©e : {cua_viewer_url}")

    # ğŸ§  L'upload du pipeline_result.json est dÃ©sormais gÃ©rÃ© par orchestrator_global.py
    result_url = None

    # ============================================================
    # ğŸ“‹ RÃ‰SULTAT UNIFIÃ‰ (pour l'API et le front)
    # ============================================================
    # RÃ©cupÃ©ration des mÃ©tadonnÃ©es CERFA depuis l'environnement
    cerfa_data = None
    cerfa_data_json = os.getenv("CERFA_DATA_JSON")
    if cerfa_data_json:
        try:
            cerfa_data = json.loads(cerfa_data_json)
        except Exception as e:
            logger.warning(f"âš ï¸ Erreur lors du parsing de CERFA_DATA_JSON : {e}")

    result = {
        "slug": slug,
        "commune": commune,
        "code_insee": code_insee,
        "maps_page": maps_page_url,
        "qr_url": qr_url,
        "carte_2d_url": url_2d,
        "carte_3d_url": url_3d,
        "output_cua": cua_url,
        "cua_viewer_url": cua_viewer_url,  # URL pour afficher le CUA en HTML
        "bucket_path": remote_dir,
        "pipeline_result_url": result_url,
        "metadata_2d": metadata_2d,
        "metadata_3d": res3d["metadata"],
        "cerfa_data": cerfa_data,  # MÃ©tadonnÃ©es CERFA
        "status": "success",
    }

    # ============================================================
    # ğŸ’¾ Ã‰CRITURE DU FICHIER RÃ‰SULTAT (lisible par l'API)
    # ============================================================
    sub_result_path = Path(OUT_DIR) / "sub_orchestrator_result.json"
    sub_result_path.write_text(json.dumps(result, indent=2, ensure_ascii=False), encoding="utf-8")
    logger.info(f"ğŸ’¾ RÃ©sultat Ã©crit dans : {sub_result_path}")

    # ============================================================
    # ğŸ—„ï¸ ENREGISTREMENT EN BASE (facultatif mais recommandÃ©)
    # ============================================================
    # ğŸ§‘â€ğŸ’¼ RÃ©cupÃ©ration des infos utilisateur depuis l'environnement
    user_id = os.getenv("USER_ID") or None
    user_email = os.getenv("USER_EMAIL") or None
    
    logger.info(f"ğŸ§© Insertion pipeline dans latresne.pipelines (slug={slug})...")
    try:
        response = supabase.schema("latresne").table("pipelines").upsert({
            "slug": slug,
            "code_insee": code_insee,
            "commune": commune,
            "status": "success",
            "bucket_path": remote_dir,
            "output_cua": cua_url,
            "carte_2d_url": url_2d,
            "carte_3d_url": url_3d,
            "qr_url": qr_url,
            "pipeline_result_url": result_url,
            "user_id": user_id,
            "user_email": user_email,
            "cerfa_data": cerfa_data,  # MÃ©tadonnÃ©es CERFA
            "metadata": result,
        }).execute()
        logger.info(f"âœ… Pipeline enregistrÃ© dans latresne.pipelines (status={getattr(response, 'status_code', '?')})")
        if user_id:
            logger.info(f"ğŸ‘¤ Pipeline associÃ© Ã  l'utilisateur : {user_email or user_id}")
    except Exception as e:
        logger.error(f"ğŸ’¥ Erreur d'insertion dans latresne.pipelines : {e}")

    # --------------------------------------------------------
    # FIN DU PIPELINE
    # --------------------------------------------------------
    logger.info("\nğŸ‰ PIPELINE CUA TERMINÃ‰ AVEC SUCCÃˆS ğŸ‰")
    logger.info(f"ğŸ“¦ Slug unique : {slug}")
    logger.info(f"ğŸ”— Lien court : {qr_url}")
    return result


# ============================================================
# â–¶ï¸ CLI
# ============================================================
if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Sous-orchestrateur pour gÃ©nÃ©ration carte 2D, 3D et CUA.")
    parser.add_argument("--wkt", required=True, help="Chemin vers le fichier WKT (unitÃ© fonciÃ¨re)")
    parser.add_argument("--out-dir", required=True, help="Dossier de sortie timestampÃ©")
    parser.add_argument("--code_insee", default="33234")
    parser.add_argument("--commune", default="latresne")
    args = parser.parse_args()

    result = generer_visualisations_et_cua_depuis_wkt(
        wkt_path=args.wkt,
        out_dir=args.out_dir,
        commune=args.commune,
        code_insee=args.code_insee
    )

    print("\nğŸ“¦ RÃ‰SULTAT FINAL :")
    print(json.dumps(result, indent=2, ensure_ascii=False))
