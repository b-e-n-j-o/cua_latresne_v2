from fastapi import FastAPI, UploadFile, File, Form, BackgroundTasks
from pathlib import Path
from datetime import datetime
import subprocess
import uuid
import json
import os

from fastapi.middleware.cors import CORSMiddleware
from supabase import create_client
from dotenv import load_dotenv

# ============================================================
# ğŸ”§ CONFIGURATION
# ============================================================
load_dotenv()

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_SERVICE_ROLE_KEY = os.getenv("SERVICE_KEY") or os.getenv("SUPABASE_SERVICE_ROLE_KEY")

# âœ… Un seul client global (cible les schÃ©mas via .schema())
supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)

app = FastAPI(title="Kerelia CUA API", version="2.1")

app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://kerelia.fr",
        "https://*.vercel.app",
        "http://localhost:5173",
        "http://localhost:3000"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Dictionnaire global pour le suivi des jobs
JOBS = {}

# ============================================================
# ğŸ”§ Fonction dâ€™exÃ©cution du pipeline (tÃ¢che asynchrone)
# ============================================================

def run_pipeline(job_id: str, pdf_path: Path, code_insee: str | None):
    """ExÃ©cute le pipeline complet en tÃ¢che de fond, avec logs live + sauvegarde."""
    BASE_DIR = Path(__file__).resolve().parent
    ORCHESTRATOR = BASE_DIR / "orchestrator_global.py"

    # PrÃ©pare les infos du job
    out = {
        "status": "running",
        "start_time": datetime.now().isoformat(),
        "pdf": pdf_path.name,
        "code_insee": code_insee,
        "logs": [],  # on conserve les lignes de logs ici
    }
    JOBS[job_id] = out

    try:
        # Commande du pipeline global
        cmd = ["python3", str(ORCHESTRATOR), "--pdf", str(pdf_path)]
        if code_insee:
            cmd.extend(["--code-insee", code_insee])

        print(f"ğŸš€ [JOB {job_id}] Lancement du pipeline : {' '.join(cmd)}")

        # ============================================================
        # ğŸ§‘â€ğŸ’¼ Passage des infos utilisateur au sous-processus
        # ============================================================
        user_id = os.getenv("USER_ID")
        user_email = os.getenv("USER_EMAIL")
        env = os.environ.copy()
        env["USER_ID"] = user_id or ""
        env["USER_EMAIL"] = user_email or ""

        # ExÃ©cution avec affichage progressif
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,  # affichage ligne par ligne
            env=env,  # ğŸ§  passage des variables d'environnement
        )

        for line in process.stdout:
            print(f"[{job_id}] {line}", end="")  # affichage live dans le terminal
            out["logs"].append(line.strip())

        process.wait(timeout=1800)
        out["returncode"] = process.returncode

        # On vÃ©rifie la sortie pipeline
        out_dirs = list((BASE_DIR / "out_pipeline").glob("*"))
        if out_dirs:
            latest_out = max(out_dirs, key=os.path.getmtime)
            result_file = latest_out / "pipeline_result.json"

            if result_file.exists():
                result_json = json.loads(result_file.read_text(encoding="utf-8"))
                out["result"] = result_json
                out["status"] = "success" if process.returncode == 0 else "error"
                
                # âœ… IntÃ©gration du rÃ©sultat du sous-orchestrateur (cartes + CUA)
                sub_result_file = latest_out / "sub_orchestrator_result.json"
                if sub_result_file.exists():
                    sub_result = json.loads(sub_result_file.read_text(encoding="utf-8"))
                    out["result_enhanced"] = sub_result
                    print(f"âœ… [JOB {job_id}] RÃ©sultat enrichi avec sub_orchestrator_result.json")
                else:
                    print(f"âš ï¸ [JOB {job_id}] sub_orchestrator_result.json introuvable")
            else:
                out["status"] = "error"
                out["error"] = "Pipeline terminÃ© mais aucun rÃ©sultat trouvÃ©."
        else:
            out["status"] = "error"
            out["error"] = "Aucun dossier out_pipeline trouvÃ©."

    except subprocess.TimeoutExpired:
        out["status"] = "timeout"
        out["error"] = "â±ï¸ Pipeline > 30 min"
        out["logs"].append("âš ï¸ Pipeline arrÃªtÃ© pour dÃ©passement de temps.")
    except Exception as e:
        out["status"] = "error"
        out["error"] = str(e)
        out["logs"].append(f"âŒ Erreur interne : {e}")
    finally:
        if pdf_path.exists():
            pdf_path.unlink()
        out["end_time"] = datetime.now().isoformat()
        JOBS[job_id] = out
        print(f"âœ… [JOB {job_id}] TerminÃ© avec statut : {out['status']}")

# ============================================================
# ğŸš€ Endpoint principal : lancement du pipeline
# ============================================================

@app.post("/analyze-cerfa")
async def analyze_cerfa(
    background_tasks: BackgroundTasks,
    pdf: UploadFile = File(...),
    code_insee: str = Form(None),
):
    """Lance le pipeline complet (CERFA â†’ UF â†’ Intersections â†’ CUA)."""
    job_id = str(uuid.uuid4())
    temp_pdf = Path(f"/tmp/cerfa_{job_id}.pdf")

    with open(temp_pdf, "wb") as f:
        f.write(await pdf.read())

    JOBS[job_id] = {
        "status": "queued",
        "created_at": datetime.now().isoformat(),
        "filename": pdf.filename,
    }

    background_tasks.add_task(run_pipeline, job_id, temp_pdf, code_insee)

    return {"success": True, "job_id": job_id}


# ============================================================
# ğŸ” Endpoint de suivi : Ã©tat du job
# ============================================================

@app.get("/status/{job_id}")
async def get_status(job_id: str):
    """Retourne lâ€™Ã©tat dâ€™un job et ses rÃ©sultats Ã©ventuels."""
    job = JOBS.get(job_id)
    if not job:
        return {"success": False, "error": "Job introuvable"}
    return job


# ============================================================
# ğŸ—‚ï¸ Endpoint : derniers rÃ©sultats
# ============================================================

@app.get("/results")
async def list_results(limit: int = 10):
    """
    Retourne les N derniers jobs terminÃ©s (success, error ou timeout).
    Utile pour afficher lâ€™historique des CUA dans ton interface.
    """
    # Filtrer les jobs terminÃ©s
    finished_jobs = [
        {"id": job_id, **data}
        for job_id, data in JOBS.items()
        if data.get("status") in {"success", "error", "timeout"}
    ]

    # Trier par date de fin (desc)
    finished_jobs.sort(key=lambda j: j.get("end_time", ""), reverse=True)

    # Limiter le nombre de rÃ©sultats
    return {
        "success": True,
        "count": len(finished_jobs),
        "results": finished_jobs[:limit],
    }


# ============================================================
# âœ… Endpoint de test / santÃ©
# ============================================================

@app.get("/health")
async def health_check():
    """VÃ©rifie que lâ€™API est en ligne."""
    return {"status": "ok", "message": "Kerelia API opÃ©rationnelle ğŸš€"}


# ============================================================
# ğŸ§¾ ENDPOINT 2 â€” DERNIERS PIPELINES (table latresne.pipelines)
# ============================================================

@app.get("/pipelines/latest")
def get_latest_pipelines(limit: int = 10):
    """
    RÃ©cupÃ¨re les derniers pipelines enregistrÃ©s pour Latresne depuis Supabase.
    """
    try:
        response = (
            supabase
            .schema("latresne")
            .table("pipelines")
            .select("*")
            .order("created_at", desc=True)
            .limit(limit)
            .execute()
        )

        pipelines = response.data or []
        return {
            "success": True,
            "count": len(pipelines),
            "pipelines": pipelines
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


# ============================================================
# ğŸ” ENDPOINT 3 â€” RETROUVER UN PIPELINE PAR SLUG
# ============================================================

@app.get("/pipelines/by_slug")
def get_pipeline_by_slug(slug: str):
    """
    Retrouve un pipeline spÃ©cifique Ã  partir de son slug unique.
    Utile pour afficher les dÃ©tails d'un CUA depuis le lien court.
    """
    try:
        response = (
            supabase
            .schema("latresne")
            .table("pipelines")
            .select("*")
            .eq("slug", slug)
            .limit(1)
            .execute()
        )

        rows = response.data or []
        if not rows:
            return {
                "success": False,
                "error": "Slug introuvable"
            }
        
        return {
            "success": True,
            "pipeline": rows[0]
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


# ============================================================
# ğŸ‘¤ ENDPOINT 4 â€” PIPELINES D'UN UTILISATEUR
# ============================================================

@app.get("/pipelines/by_user")
def get_pipelines_by_user(user_id: str, limit: int = 15):
    """
    RÃ©cupÃ¨re les pipelines d'un utilisateur spÃ©cifique.
    Utile pour afficher l'historique personnel dans l'interface.
    """
    try:
        response = (
            supabase
            .schema("latresne")
            .table("pipelines")
            .select("*")
            .eq("user_id", user_id)
            .order("created_at", desc=True)
            .limit(limit)
            .execute()
        )

        pipelines = response.data or []
        return {
            "success": True,
            "count": len(pipelines),
            "pipelines": pipelines
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


# ============================================================

# ============================================================
# ğŸ§  ENDPOINT DEBUG â€” TEST SUPABASE (latresne + public)
# ============================================================

@app.get("/debug/supabase")
def debug_supabase():
    """
    VÃ©rifie la connectivitÃ© Ã  Supabase et l'accÃ¨s aux schÃ©mas latresne + public.
    Retourne un petit rÃ©sumÃ© des lignes accessibles dans les tables clÃ©s.
    """
    try:
        print("ğŸ§© [DEBUG] VÃ©rification connexion Supabase...")
        
        # Test 1 : latresne.pipelines
        res_latresne = (
            supabase
            .schema("latresne")
            .table("pipelines")
            .select("id, slug, created_at")
            .limit(3)
            .execute()
        )
        nb_latresne = len(res_latresne.data or [])
        print(f"âœ… [DEBUG] latresne.pipelines OK â€” {nb_latresne} ligne(s) visibles")

        # Test 2 : public.shortlinks
        res_public = (
            supabase
            .schema("public")
            .table("shortlinks")
            .select("slug, target_url, created_at")
            .limit(3)
            .execute()
        )
        nb_public = len(res_public.data or [])
        print(f"âœ… [DEBUG] public.shortlinks OK â€” {nb_public} ligne(s) visibles")

        return {
            "status": "ok",
            "latresne": {
                "rows": nb_latresne,
                "examples": res_latresne.data
            },
            "public": {
                "rows": nb_public,
                "examples": res_public.data
            }
        }

    except Exception as e:
        print(f"ğŸ’¥ [DEBUG] Erreur connexion Supabase : {e}")
        return {
            "status": "error",
            "details": str(e)
        }
