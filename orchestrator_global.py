#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
orchestrator_global.py ‚Äî Pipeline global KERELIA (phase 2)
-----------------------------------------------------------
1Ô∏è‚É£ Analyse du CERFA via Gemini (analyse_gemini.py)
2Ô∏è‚É£ V√©rification unit√© fonci√®re via WFS IGN (verification_unite_fonciere.py)
3Ô∏è‚É£ Intersections avec couches urbanistiques (intersections.py)
-----------------------------------------------------------
√âtapes suivantes pr√©vues :
4Ô∏è‚É£ G√©n√©ration cartes 2D / 3D
5Ô∏è‚É£ G√©n√©ration certificat d'urbanisme DOCX
"""

import subprocess
subprocess.run(["pip", "list"], check=True)  # Liste les packages install√©s
import json
import logging
import sys
import os
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from supabase import create_client

# ============================================================
# CONFIG
# ============================================================
load_dotenv()

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)-8s | %(message)s",
    datefmt="%H:%M:%S"
)
logger = logging.getLogger("orchestrator_global")

# Configuration Supabase pour upload final
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SERVICE_KEY") or os.getenv("SUPABASE_SERVICE_ROLE_KEY")
SUPABASE_BUCKET = "visualisation"

CERFA_ANALYSE_SCRIPT = "./CERFA_ANALYSE/analyse_gemini.py"
VERIF_UF_SCRIPT = "./CERFA_ANALYSE/verification_unite_fonciere.py"
INTERSECTIONS_SCRIPT = "./INTERSECTIONS/intersections.py"
SUB_ORCHESTRATOR_CUA = "./CUA/sub_orchestrator_cua.py"

timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
OUT_DIR = Path("./out_pipeline") / timestamp
OUT_DIR.mkdir(parents=True, exist_ok=True)

# ============================================================
# UTILS
# ============================================================
def run_subprocess(cmd, desc):
    """Ex√©cute une commande subprocess et logge les erreurs proprement."""
    logger.info(f"\nüöÄ √âtape : {desc}")
    try:
        subprocess.run(cmd, check=True, cwd=Path(__file__).parent)
    except subprocess.CalledProcessError as e:
        logger.error(f"üí• √âchec lors de {desc}: {e}")
        sys.exit(1)

# ============================================================
# PIPELINE PRINCIPAL
# ============================================================
def orchestrer_pipeline(pdf_path: str, code_insee: str):
    """
    Orchestration compl√®te du process CERFA ‚Üí UF ‚Üí Intersections
    """
    pdf = Path(pdf_path)
    if not pdf.exists():
        logger.error(f"‚ùå Fichier PDF introuvable : {pdf}")
        sys.exit(1)

    logger.info(f"üìÑ Analyse du fichier CERFA : {pdf.name}")
    
    cerfa_json_path = OUT_DIR / "cerfa_result.json"
    uf_json_path = OUT_DIR / "rapport_unite_fonciere.json"
    geom_wkt_path = OUT_DIR / "geom_unite_fonciere.wkt"
    intersections_json_path = OUT_DIR / "rapport_intersections.json"

    # -------------------------------
    # √âTAPE 1 : ANALYSE GEMINI
    # -------------------------------
    run_subprocess([
        "python3", CERFA_ANALYSE_SCRIPT,
        "--pdf", str(pdf),
        "--out-json", str(cerfa_json_path),
        "--out-dir", str(OUT_DIR),
        "--insee-csv", "../CONFIG/v_commune_2025.csv"
    ], "Analyse du CERFA (Gemini)")

    cerfa_data = json.load(open(cerfa_json_path))
    data = cerfa_data.get("data", {})
    insee = data.get("commune_insee") or code_insee
    if not insee:
        logger.error("‚ùå Code INSEE non trouv√© dans l‚Äôanalyse CERFA.")
        sys.exit(1)

    # -------------------------------
    # √âTAPE 2 : VALIDATION UNIT√â FONCI√àRE
    # -------------------------------
    run_subprocess([
        "python3", VERIF_UF_SCRIPT,
        "--cerfa-json", str(cerfa_json_path),
        "--code-insee", insee,
        "--out", str(uf_json_path),
        "--out-dir", str(OUT_DIR)
    ], "V√©rification unit√© fonci√®re")

    uf_result = json.load(open(uf_json_path))
    logger.info(f"üìä R√©sultat UF : {uf_result['message']}")
    if not uf_result.get("success", False):
        logger.warning("‚ùå Arr√™t du pipeline : unit√© fonci√®re non valide.")
        sys.exit(1)

    # V√©rification que la g√©om√©trie WKT a bien √©t√© g√©n√©r√©e dans OUT_DIR
    if not geom_wkt_path.exists():
        logger.error(f"‚ùå Fichier de g√©om√©trie d'unit√© fonci√®re manquant : {geom_wkt_path}")
        sys.exit(1)

    # -------------------------------
    # √âTAPE 3 : INTERSECTIONS
    # -------------------------------
    run_subprocess([
        "python3", INTERSECTIONS_SCRIPT,
        "--geom-wkt", str(geom_wkt_path),
        "--out-dir", str(OUT_DIR)
    ], "Analyse des intersections")

    # R√©cup√©ration du rapport g√©n√©r√© (le nom d√©pend du script d'intersections)
    json_candidates = list(OUT_DIR.glob("rapport_intersections_*.json"))
    if json_candidates:
        json_candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)
        latest_report = json_candidates[0]
        logger.info(f"üìë Rapport d'intersection g√©n√©r√© : {latest_report.name}")
    else:
        logger.warning("‚ö†Ô∏è Aucun rapport d'intersection trouv√©.")
        latest_report = None

    logger.info("‚úÖ √âtape intersections termin√©e ‚Äî suite du traitement possible.")
    logger.info("üß© √âtapes suivantes √† venir : cartes 2D/3D, CUA...")

    # -------------------------------
    # √âTAPE 4 : G√âN√âRATION CARTES + CUA
    # -------------------------------
    if latest_report and geom_wkt_path.exists():
        logger.info("\nüó∫Ô∏è  Lancement de la g√©n√©ration des cartes 2D/3D et du CUA...")
        try:
            run_subprocess([
                "python3", SUB_ORCHESTRATOR_CUA,
                "--wkt", str(geom_wkt_path),
                "--code_insee", insee,
                "--commune", "latresne",
                "--out-dir", str(OUT_DIR)  # ‚úÖ
            ], "G√©n√©ration cartes + CUA")
            logger.info("‚úÖ Sous-orchestrateur CUA ex√©cut√© avec succ√®s.")
        except Exception as e:
            logger.error(f"üí• √âchec du sous-orchestrateur CUA : {e}")
    else:
        logger.warning("‚ö†Ô∏è Impossible de lancer la g√©n√©ration CUA : g√©om√©trie ou rapport manquant.")

    # -------------------------------
    # RETOUR GLOBAL
    # -------------------------------
    result = {
        "cerfa_result": str(cerfa_json_path),
        "uf_result": str(uf_json_path),
        "geom_wkt": str(geom_wkt_path),
        "intersections": str(latest_report) if latest_report else None
    }

    # Int√©gration du r√©sultat global du sous-orchestrateur, s'il a produit un fichier final
    cua_docx = OUT_DIR / "CUA_unite_fonciere.docx"
    if cua_docx.exists():
        result["cua_docx"] = str(cua_docx)

    result_path = OUT_DIR / "pipeline_result.json"
    result_path.write_text(json.dumps(result, indent=2, ensure_ascii=False), encoding="utf-8")

    logger.info(f"\nüéâ PIPELINE TERMIN√â AVEC SUCC√àS üéâ")
    logger.info(f"üì¶ R√©sum√© enregistr√© dans : {result_path}")

    # ============================================================
    # üì§ UPLOAD FINAL : pipeline_result.json vers Supabase
    # ============================================================
    logger.info("\nüì§ Upload final des r√©sultats JSON vers Supabase...")
    
    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        
        # R√©cup√©rer le slug depuis sub_orchestrator_result.json
        sub_result_file = OUT_DIR / "sub_orchestrator_result.json"
        slug = None
        if sub_result_file.exists():
            sub_result = json.loads(sub_result_file.read_text(encoding="utf-8"))
            slug = sub_result.get("slug")
        
        if not slug:
            logger.warning("‚ö†Ô∏è Slug introuvable ‚Äî impossible d'uploader les r√©sultats JSON.")
        else:
            # Fichiers potentiels √† uploader
            result_files = [
                OUT_DIR / "pipeline_result.json",
                OUT_DIR / "sub_orchestrator_result.json"
            ]
            
            for file_path in result_files:
                if file_path.exists():
                    remote_path = f"{slug}/{file_path.name}"
                    try:
                        with open(file_path, "rb") as f:
                            supabase.storage.from_(SUPABASE_BUCKET).upload(
                                remote_path, f.read(), {"upsert": "true"}
                            )
                        remote_url = (
                            f"{SUPABASE_URL}/storage/v1/object/public/"
                            f"{SUPABASE_BUCKET}/{remote_path}"
                        )
                        logger.info(f"‚úÖ {file_path.name} upload√© vers Supabase : {remote_url}")
                    except Exception as e:
                        logger.error(f"üí• Erreur upload {file_path.name} : {e}")
                else:
                    logger.warning(f"‚ö†Ô∏è Fichier {file_path.name} non trouv√© pour upload.")
            
            # ============================================================
            # üë§ MISE √Ä JOUR : user_id / user_email dans la table pipelines
            # ============================================================
            try:
                user_id = os.getenv("USER_ID")
                user_email = os.getenv("USER_EMAIL")

                if slug and (user_id or user_email):
                    logger.info(f"üë§ Mise √† jour des infos utilisateur pour le pipeline {slug}...")
                    update_data = {}
                    if user_id:
                        update_data["user_id"] = user_id
                    if user_email:
                        update_data["user_email"] = user_email

                    supabase.schema("latresne").table("pipelines").update(update_data).eq("slug", slug).execute()
                    logger.info(f"‚úÖ user_id / user_email mis √† jour : {user_id or 'None'} / {user_email or 'None'}")
                else:
                    logger.info("‚ö†Ô∏è Aucun USER_ID ou USER_EMAIL trouv√© dans l'environnement ‚Äî pas de mise √† jour utilisateur.")
            except Exception as e:
                logger.error(f"üí• Erreur lors de la mise √† jour des infos utilisateur : {e}")
            
            # ============================================================
            # üß† MISE √Ä JOUR : pipeline_result_url dans la table pipelines
            # ============================================================
            try:
                if (OUT_DIR / "pipeline_result.json").exists():
                    result_url = (
                        f"{SUPABASE_URL}/storage/v1/object/public/"
                        f"{SUPABASE_BUCKET}/{slug}/pipeline_result.json"
                    )

                    logger.info("üß© Mise √† jour du champ pipeline_result_url dans la base...")
                    supabase.schema("latresne").table("pipelines").update({
                        "pipeline_result_url": result_url
                    }).eq("slug", slug).execute()
                    logger.info(f"‚úÖ pipeline_result_url mis √† jour : {result_url}")
            except Exception as e:
                logger.error(f"üí• Erreur lors de la mise √† jour du pipeline_result_url : {e}")
    
    except Exception as e:
        logger.error(f"üí• Erreur lors de l'upload final : {e}")

# ============================================================
# CLI
# ============================================================
if __name__ == "__main__":
    import argparse
    ap = argparse.ArgumentParser(description="Orchestrator global ‚Äî KERELIA (phase 2)")
    ap.add_argument("--pdf", required=True, help="Chemin vers le CERFA PDF")
    ap.add_argument("--code-insee", default=None, help="Code INSEE (fallback si non trouv√©)")
    args = ap.parse_args()

    orchestrer_pipeline(args.pdf, args.code_insee)
